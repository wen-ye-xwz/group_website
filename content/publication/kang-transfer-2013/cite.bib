@misc{kang_transfer_2013,
 abstract = {The increasing volume of short texts generated on social media sites, such as Twitter or Facebook, creates a great demand for effective and efficient topic modeling approaches. While latent Dirichlet allocation (LDA) can be applied, it is not optimal due to its weakness in handling short texts with fast-changing topics and scalability concerns. In this paper, we propose a transfer learning approach that utilizes abundant labeled documents from other domains (such as Yahoo! News or Wikipedia) to improve topic modeling, with better model fitting and result interpretation. Specifically, we develop Transfer Hierarchical LDA (thLDA) model, which incorporates the label information from other domains via informative priors. In addition, we develop a parallel implementation of our model for large-scale applications. We demonstrate the effectiveness of our thLDA model on both a microblogging dataset and standard text collections including AP and RCV1 datasets.},
 annote = {Comment: 2012 SIAM International Conference on Data Mining (SDM12) Pages: \564-575\},
 author = {Kang, Jeon-Hyung and Ma, Jun and Liu, Yan},
 doi = {10.48550/arXiv.1301.5686},
 file = {Preprint PDF:C\:\\Users\\selvam\\Zotero\\storage\\QUYFARHG\\Kang et al. - 2013 - Transfer Topic Modeling with Ease and Scalability.pdf:application/pdf;Snapshot:C\:\\Users\\selvam\\Zotero\\storage\\5P6LNF6D\\1301.html:text/html},
 keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning},
 month = {January},
 note = {arXiv:1301.5686 [cs]},
 publisher = {arXiv},
 title = {Transfer Topic Modeling with Ease and Scalability},
 url = {http://arxiv.org/abs/1301.5686},
 urldate = {2025-01-09},
 year = {2013}
}
