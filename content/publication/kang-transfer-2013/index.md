---
title: Transfer Topic Modeling with Ease and Scalability
authors:
- Jeon-Hyung Kang
- Jun Ma
- Yan Liu
date: '2013-01-01'
publishDate: '2025-01-09T23:43:57.468604Z'
publication_types:
- manuscript
publication: '*arXiv*'
doi: 10.48550/arXiv.1301.5686
abstract: The increasing volume of short texts generated on social media sites, such
  as Twitter or Facebook, creates a great demand for effective and efficient topic
  modeling approaches. While latent Dirichlet allocation (LDA) can be applied, it
  is not optimal due to its weakness in handling short texts with fast-changing topics
  and scalability concerns. In this paper, we propose a transfer learning approach
  that utilizes abundant labeled documents from other domains (such as Yahoo! News
  or Wikipedia) to improve topic modeling, with better model fitting and result interpretation.
  Specifically, we develop Transfer Hierarchical LDA (thLDA) model, which incorporates
  the label information from other domains via informative priors. In addition, we
  develop a parallel implementation of our model for large-scale applications. We
  demonstrate the effectiveness of our thLDA model on both a microblogging dataset
  and standard text collections including AP and RCV1 datasets.
tags:
- Computer Science - Computation and Language
- Computer Science - Machine Learning
- Statistics - Machine Learning
links:
- name: URL
  url: http://arxiv.org/abs/1301.5686
---
