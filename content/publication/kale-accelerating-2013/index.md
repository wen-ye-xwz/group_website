---
title: Accelerating Active Learning with Transfer Learning
authors:
- David Kale
- Yan Liu
date: '2013-12-01'
publishDate: '2025-01-09T23:43:57.429747Z'
publication_types:
- paper-conference
publication: '*2013 IEEE 13th International Conference on Data Mining*'
doi: 10.1109/ICDM.2013.160
abstract: "Active learning, transfer learning, and related techniques are unified
  by a core theme: efficient and effective use of available data. Active learning
  offers scalable solutions for building effective supervised learning models while
  minimizing annotation effort. Transfer learning utilizes existing labeled data from
  one task to help learning related tasks for which limited labeled data are available.
  There has been limited research, however, on how to combine these two techniques.
  In this paper, we present a simple and principled transfer active learning framework
  that leverages pre-existing labeled data from related tasks to improve the performance
  of an active learner. We derive an intuitive bound on generalization error for the
  classifiers learned by this algorithm that provides insight into the algorithm's
  behavior and the problem in general. Experimental results using several well-known
  transfer learning data sets confirm our theoretical analysis and demonstrate the
  effectiveness of our approach."
tags:
- Acceleration
- Machine Learning
- Training
- Active Learning
- Algorithm design and analysis
- Labeling
- Learning Theory
- Query processing
- Supervised learning
- Transfer Learning
- Upper bound
links:
- name: URL
  url: https://ieeexplore.ieee.org/abstract/document/6729602
---
