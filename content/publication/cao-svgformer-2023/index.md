---
title: 'SVGformer: Representation Learning for Continuous Vector Graphics using Transformers'
authors:
- Defu Cao
- Zhaowen Wang
- Jose Echevarria
- Yan Liu
date: '2023-06-01'
publishDate: '2025-01-08T06:22:33.407920Z'
publication_types:
- paper-conference
publication: '*2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition
  (CVPR)*'
doi: 10.1109/CVPR52729.2023.00973
abstract: 'Advances in representation learning have led to great success in understanding
  and generating data in various domains. However, in modeling vector graphics data,
  the pure data-driven approach often yields unsatisfactory results in downstream
  tasks as existing deep learning methods often require the quantization of SVG parameters
  and cannot exploit the geometric properties explicitly. In this paper, we propose
  a transformer-based representation learning model (SVG-former) that directly operates
  on continuous input values and manipulates the geometric information of SVG to encode
  outline details and long-distance dependencies. SVGfomer can be used for various
  downstream tasks: reconstruction, classification, interpolation, retrieval, etc.
  We have conducted extensive experiments on vector font and icon datasets to show
  that our model can capture high-quality representation information and outperform
  the previous state-of-the-art on downstream tasks significantly.'
tags:
- Deep learning
- Deep learning architectures and techniques
- Graphics
- Interpolation
- Quantization (signal)
- Representation learning
- Semantics
- Transformers
links:
- name: URL
  url: https://ieeexplore.ieee.org/document/10204069
---
