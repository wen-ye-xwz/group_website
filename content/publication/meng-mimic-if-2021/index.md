---
title: 'MIMIC-IF: Interpretability and Fairness Evaluation of Deep Learning Models
  on MIMIC-IV Dataset'
authors:
- Chuizheng Meng
- Loc Trinh
- Nan Xu
- Yan Liu
date: '2021-02-01'
publishDate: '2025-01-08T06:22:33.444530Z'
publication_types:
- manuscript
publication: '*arXiv*'
doi: 10.48550/arXiv.2102.06761
abstract: The recent release of large-scale healthcare datasets has greatly propelled
  the research of data-driven deep learning models for healthcare applications. However,
  due to the nature of such deep black-boxed models, concerns about interpretability,
  fairness, and biases in healthcare scenarios where human lives are at stake call
  for a careful and thorough examinations of both datasets and models. In this work,
  we focus on MIMIC-IV (Medical Information Mart for Intensive Care, version IV),
  the largest publicly available healthcare dataset, and conduct comprehensive analyses
  of dataset representation bias as well as interpretability and prediction fairness
  of deep learning models for in-hospital mortality prediction. In terms of interpretabilty,
  we observe that (1) the best performing interpretability method successfully identifies
  critical features for mortality prediction on various prediction models; (2) demographic
  features are important for prediction. In terms of fairness, we observe that (1)
  there exists disparate treatment in prescribing mechanical ventilation among patient
  groups across ethnicity, gender and age; (2) all of the studied mortality predictors
  are generally fair while the IMV-LSTM (Interpretable Multi-Variable Long Short-Term
  Memory) model provides the most accurate and unbiased predictions across all protected
  groups. We further draw concrete connections between interpretability methods and
  fairness metrics by showing how feature importance from interpretability methods
  can be beneficial in quantifying potential disparities in mortality predictors.
tags:
- Computer Science - Artificial Intelligence
- Computer Science - Machine Learning
links:
- name: URL
  url: http://arxiv.org/abs/2102.06761
---
