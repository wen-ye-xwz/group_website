@article{jin_new_2003,
 abstract = {AdaBoost has proved to be an effective method to improve the performance of base classifiers both theoretically and empirically. However, previous studies have shown that AdaBoost might suffer from the overfitting problem, especially for noisy data. In addition, most current work on boosting assumes that the combination weights are fixed constants and therefore does not take particular input patterns into consideration. In this paper, we present a new boosting algorithm, “WeightBoost”, which tries to solve these two problems by introducing an input-dependent regularization factor to the combination weight. Similarly to AdaBoost, we derive a learning procedure for WeightBoost, which is guaranteed to minimize training errors. Empirical studies on eight different UCI data sets and one text categorization data set show that WeightBoost almost always achieves a considerably better classification accuracy than AdaBoost. Furthermore, experiments on data with artificially controlled noise indicate that the WeightBoost is more robust to noise than AdaBoost.},
 author = {Jin, Rong and Liu, Yan and Si, Luo and Carbonell, Jaime G. and Hauptmann, Alexander G.},
 copyright = {In Copyright},
 doi = {10.1184/R1/6620711.V1},
 keywords = {80399 Computer Software not elsewhere classified, FOS: Computer and information sciences},
 note = {Artwork Size: 215209 Bytes
Publisher: Carnegie Mellon University},
 pages = {215209 Bytes},
 title = {A New Boosting Algorithm Using Input-Dependent Regularizer},
 url = {https://kilthub.cmu.edu/articles/A_New_Boosting_Algorithm_Using_Input-Dependent_Regularizer/6620711/1},
 urldate = {2025-01-10},
 year = {2003}
}
