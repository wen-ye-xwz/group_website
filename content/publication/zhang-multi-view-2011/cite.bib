@inproceedings{zhang_multi-view_2011,
 abstract = {Transfer learning has been proposed to address the problem of scarcity of labeled data in the target domain by leveraging the data from the source domain. In many real world applications, data is often represented from different perspectives, which correspond to multiple views. For example, a web page can be described by its contents and its associated links. However, most existing transfer learning methods fail to capture the multi-view \nature\, and might not be best suited for such applications.To better leverage both the labeled data from the source domain and the features from different views, \this paper proposes\ a general framework: Multi-View Transfer Learning with a Large Margin Approach (MVTL-LM). On one hand, labeled data from the source domain is effectively utilized to construct a large margin classifier; on the other hand, the data from both domains is employed to impose consistencies among multiple views. As an instantiation of this framework, we propose an efficient optimization method, which is guaranteed to converge to ε precision in O(1/ε) steps. Furthermore, we analyze its error bound, which improves over existing results of related methods. An extensive set of experiments are conducted to demonstrate the advantages of our proposed method over state-of-the-art techniques.},
 address = {New York, NY, USA},
 author = {Zhang, Dan and He, Jingrui and Liu, Yan and Si, Luo and Lawrence, Richard},
 booktitle = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining},
 doi = {10.1145/2020408.2020593},
 isbn = {978-1-4503-0813-7},
 month = {August},
 pages = {1208--1216},
 publisher = {Association for Computing Machinery},
 series = {KDD '11},
 title = {Multi-view transfer learning with a large margin approach},
 url = {https://doi.org/10.1145/2020408.2020593},
 urldate = {2025-01-09},
 year = {2011}
}
