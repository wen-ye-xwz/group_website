@inproceedings{kamra_deepfp_2019,
 abstract = {Finding Nash equilibrium in continuous action spaces is a challenging problem and has applications in domains such as protecting geographic areas from potential attackers. We present DeepFP, an approximate extension of fictitious play in continuous action spaces. DeepFP represents players’ approximate best responses via generative neural networks which are highly expressive implicit density approximators. It additionally uses a game-model network which approximates the players’ expected payoffs given their actions, and trains the networks end-to-end in a model-based learning regime. Further, DeepFP allows using domain-specific oracles if available and can hence exploit techniques such as mathematical programming to compute best responses for structured games. We demonstrate stable convergence to Nash equilibrium on several classic games and also apply DeepFP to a large forest security domain with a novel defender best response oracle. We show that DeepFP learns strategies robust to adversarial exploitation and scales well with growing number of players’ resources.},
 address = {Berlin, Heidelberg},
 author = {Kamra, Nitin and Gupta, Umang and Wang, Kai and Fang, Fei and Liu, Yan and Tambe, Milind},
 booktitle = {Decision and Game Theory for Security: 10th International Conference, GameSec 2019, Stockholm, Sweden, October 30 – November 1, 2019, Proceedings},
 doi = {10.1007/978-3-030-32430-8_15},
 isbn = {978-3-030-32429-2},
 month = {October},
 pages = {238--258},
 publisher = {Springer-Verlag},
 title = {DeepFP for Finding Nash Equilibrium in Continuous Action Spaces},
 url = {https://doi.org/10.1007/978-3-030-32430-8_15},
 urldate = {2025-01-07},
 year = {2019}
}
