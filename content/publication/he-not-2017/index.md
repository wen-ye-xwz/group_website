---
title: Not Enough Data? Joint Inferring Multiple Diffusion Networks via Network Generation
  Priors
authors:
- Xinran He
- Yan Liu
date: '2017-02-01'
publishDate: '2025-01-08T12:27:49.348603Z'
publication_types:
- paper-conference
publication: '*Proceedings of the Tenth ACM International Conference on Web Search
  and Data Mining*'
doi: 10.1145/3018661.3018675
abstract: 'Network Inference, i.e., discovering latent diffusion networks from observed
  cascades, has been studied extensively in recent years, leading to a series of excellent
  work. However, it has been observed that the accuracy of existing methods deteriorates
  significantly when the number of cascades are limited (compared with the large number
  of nodes), which is the norm in real world applications. Meanwhile, we are able
  to collect cascades on many different topics or over a long time period: the associated
  influence networks (either topic-specific or time-specific) are highly correlated
  while the number of cascade observations associated with each network is very limited.
  In this work, we propose a generative model, referred to as the MultiCascades model
  (MCM), to address the challenge of data scarcity by exploring the commonality between
  multiple related diffusion networks. MCM builds a hierarchical graphical model,
  where all the diffusion networks share the same network prior, e.g., the popular
  Stochastic Blockmodels or the latent space models. The parameters of the network
  priors can be effectively learned by gleaning evidence from a large number of inferred
  networks. In return, each individual network can be inferred more accurately thanks
  to the prior information. Furthermore, we develop efficient inference and learning
  algorithms so that MCM is scalable for practical applications. The results on both
  synthetic datasets and real-world datasets demonstrate that MCM infers both topic-specific
  and time-varying diffusion networks more accurately.'
links:
- name: URL
  url: https://dl.acm.org/doi/10.1145/3018661.3018675
---
